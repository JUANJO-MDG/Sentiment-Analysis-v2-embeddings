# Sentiment Analysis v2 üöÄ

Un sistema completo de an√°lisis de sentimientos utilizando **LightGBM** y **Sentence Transformers** con una arquitectura moderna que incluye API REST, caching inteligente y optimizaciones de rendimiento.

## üìã Tabla de Contenidos

- [Caracter√≠sticas](#caracter√≠sticas)
- [Arquitectura](#arquitectura)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso](#uso)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [API Endpoints](#api-endpoints)
- [Modelos](#modelos)
- [Procesamiento de Datos](#procesamiento-de-datos)
- [Desarrollo](#desarrollo)
- [Testing](#testing)
- [Contribuci√≥n](#contribuci√≥n)
- [Licencia](#licencia)

## ‚ú® Caracter√≠sticas

### üéØ An√°lisis de Sentimientos

- **3 clases de sentimiento**: Positivo (1), Negativo (0), Neutral (2)
- **Modelo LightGBM** optimizado con hyperparameter tuning
- **Embeddings** generados con `sentence-transformers/all-MiniLM-L6-v2`
- **Alta precisi√≥n** en clasificaci√≥n multiclase

### üîß Arquitectura Moderna

- **API REST** construida con FastAPI
- **Caching inteligente** para embeddings y modelos
- **Procesamiento en paralelo** para datasets grandes
- **Optimizaciones de memoria** y rendimiento

### üöÄ Funcionalidades Avanzadas

- **Caching autom√°tico** de modelos en disco
- **Batch processing** optimizado para m√∫ltiples predicciones
- **Middleware CORS** para integraci√≥n frontend
- **Logging detallado** para debugging y monitoreo
- **Health checks** y endpoints de testing

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend         ‚îÇ       ‚îÇ      FastAPI      ‚îÇ       ‚îÇ      ML Pipeline   ‚îÇ
‚îÇ   (Gradio)         ‚îÇ ‚óÑ‚îÄ‚îÄ‚ñ∫ ‚îÇ    REST API       ‚îÇ ‚óÑ‚îÄ‚îÄ‚ñ∫ ‚îÇ     ightGBM        ‚îÇ
‚îÇ                    ‚îÇ       ‚îÇ                   ‚îÇ       ‚îÇ    + Embeddings.   ‚îÇ 
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ       Data Layer   ‚îÇ
                    ‚îÇ       Caching &    ‚îÇ
                    ‚îÇ      Preprocessing ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üì¶ Instalaci√≥n

### Prerrequisitos

- Python 3.8+
- pip o conda
- Git

### Configuraci√≥n del Entorno

1. **Clonar el repositorio**

```bash
git clone https://github.com/JUANJO-MDG/Sentiment-Analysis-v2-embeddings.git
cd "Sentiment Analysis v2"
```

2. **Crear entorno virtual**

```bash
python -m venv .venv
source .venv/bin/activate  # En Linux/Mac
# o
.venv\Scripts\activate     # En Windows
```

3. **Instalar dependencias**

```bash
pip install -r requirements.txt
```

### Dependencias Principales

- **FastAPI** (0.116.1) - Framework web moderno
- **LightGBM** (4.6.0) - Modelo de gradient boosting
- **sentence-transformers** (5.1.0) - Generaci√≥n de embeddings
- **scikit-learn** (1.7.1) - M√©tricas y evaluaci√≥n
- **pandas** (2.3.2) - Manipulaci√≥n de datos
- **uvicorn** (0.35.0) - Servidor ASGI

## üöÄ Uso

### API REST

1. **Iniciar el servidor**

```bash
python src/api/main.py
```

El servidor se ejecutar√° en `http://localhost:8000`. Tambi√©n puedes ejecutar el servidor de forma sencilla junto con la interfaz de gradio gradio en `http://localhost:8000/gradio`

2. **Hacer predicciones**

```bash
# Health check
curl http://localhost:8000/model/api/v2/health

# Test endpoint
curl http://localhost:8000/model/api/v2/test

# Predicci√≥n
curl -X POST "http://localhost:8000/model/api/v2/predict" \
     -H "Content-Type: application/json" \
     -d '{"message": "I love this product!"}'
```

### Uso Program√°tico

```python
from src.model.prediction_service import get_prediction_service

# Obtener servicio (singleton con caching)
service = get_prediction_service()

# Predicci√≥n individual
label, score = service.predict_sentiment("This is amazing!")
print(f"Sentiment: {label} (score: {score})")

# Predicci√≥n por lotes (optimizada)
texts = ["I love it!", "This is terrible", "It's okay"]
results = service.predict_batch_optimized(texts)
```

### Testing del Modelo

(TESTING)

## üìÅ Estructura del Proyecto

```
Sentiment Analysis v2/
‚îú‚îÄ‚îÄ üìÅ src/                          # C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ api/                      # API REST con FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Aplicaci√≥n principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ routes/               # Endpoints de la API
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ route.py             # Rutas de predicci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ schemas/              # Modelos de datos Pydantic
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ model_schemas.py     # Esquemas request/response
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ model/                    # L√≥gica de modelos ML
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py                 # Creaci√≥n y configuraci√≥n LightGBM
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prediction_service.py    # Servicio de predicci√≥n con caching
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ models/                   # Gesti√≥n de modelos y embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils.py                 # M√©tricas de evaluaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ embeddings/           # Gesti√≥n de embeddings
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ emb_model.py         # Modelo de embeddings con caching
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ emb_data.py          # Carga y generaci√≥n de embeddings
‚îÇ   ‚îÇ       üìÅ predictor/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ lgbm_sentiment_predictor.joblib  # Modelo LightGBM
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ data/                     # Procesamiento de datos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py         # Limpieza y procesamiento de texto
‚îÇ   ‚îÇ
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ frontend/                 # Interfaz web
‚îÇ       ‚îî‚îÄ‚îÄ gr_interface.py          # Interfaz Gradio (TODO)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models_cache/                 # Cache de modelos embeddings
‚îú‚îÄ‚îÄ üìÅ data/                         # Datasets y datos procesados
‚îú‚îÄ‚îÄ üìÅ tests/
‚îú‚îÄ‚îÄ .dockerignore                    # Archivos ignorados por Docker
‚îú‚îÄ‚îÄ Dockerfile                       # Instrucciones Docker
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias Python
‚îú‚îÄ‚îÄ .gitignore                       # Archivos ignorados por Git
‚îî‚îÄ‚îÄ README.md                        # Este archivo
```

## üîå API Endpoints

### Base URL: `http://localhost:8000/model/api/v2`

| Endpoint   | M√©todo | Descripci√≥n                         | Request                | Response                                                 |
| ---------- | ------ | ----------------------------------- | ---------------------- | -------------------------------------------------------- |
| `/health`  | GET    | Health check del servicio           | -                      | `{"status": "healthy", "service": "sentiment-analysis"}` |
| `/test`    | GET    | Test autom√°tico con mensaje ejemplo | -                      | `{"status": "success", "prediction": "...", "score": 1}` |
| `/predict` | POST   | Predicci√≥n de sentimiento           | `{"message": "texto"}` | `{"sentiment": "Positive\|Negative\|Neutral"}`           |

### Ejemplos de Uso

```javascript
// JavaScript/Frontend
fetch("http://localhost:8000/model/api/v2/predict", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    message: "I absolutely love this new feature!",
  }),
})
  .then((response) => response.json())
  .then((data) => console.log(data.sentiment));
```

```python
# Python
import requests

response = requests.post(
    'http://localhost:8000/model/api/v2/predict',
    json={'message': 'This product is terrible'}
)
print(response.json()['sentiment'])  # "Negative"
```

## ü§ñ Modelos

### LightGBM Classifier

- **Objetivo**: Clasificaci√≥n multiclase (3 clases)
- **M√©trica**: Multi-class log-loss
- **Caracter√≠sticas**: Optimizado con RandomizedSearchCV
- **Archivo**: `src/models/predictor/lgbm_sentiment_predictor.joblib`

### Sentence Transformer

- **Modelo**: `sentence-transformers/all-MiniLM-L6-v2`
- **Dimensiones**: 384 features por embedding
- **Caching**: Autom√°tico en disco para evitar re-descargas
- **Ubicaci√≥n Cache**: `models_cache/all-MiniLM-L6-v2/`

### Rendimiento

- **Precisi√≥n**: 75% (dependiendo del dataset)
- **Velocidad**:
  - Primera predicci√≥n: ~2-3s (carga de modelos)
  - Predicciones siguientes: ~50-100ms
  - Batch processing: ~10-20ms por texto

## üìä Procesamiento de Datos

### Pipeline de Limpieza

1. **Conversi√≥n a min√∫sculas**
2. **Eliminaci√≥n de URLs** (`http://`, `www.`, `https://`)
3. **Eliminaci√≥n de menciones** (`@usuario`, `#hashtag`)
4. **Eliminaci√≥n de n√∫meros**
5. **Eliminaci√≥n de emojis**
6. **Eliminaci√≥n de puntuaci√≥n**
7. **Normalizaci√≥n de espacios en blanco**

### Optimizaciones

- **Patrones RegEx pre-compilados** para m√°ximo rendimiento
- **Procesamiento en paralelo** utilizando multiprocessing
- **Batch processing** para embeddings
- **Caching de embeddings** en formato NumPy

### Formato de Datos

```python
# Dataset esperado
df = pd.DataFrame({
    'Text': ['I love this!', 'This is bad', 'It\'s okay'],
    'Label': [1, 0, 2]  # 1=Positive, 0=Negative, 2=Neutral
})
```

## üõ†Ô∏è Desarrollo

### Configuraci√≥n del Entorno de Desarrollo

```bash
# Instalar dependencias de desarrollo
pip install -r requirements.txt

# Configurar pre-commit hooks (opcional)
pip install pre-commit
pre-commit install
```

### Estructura de Desarrollo

- **Logging**: Configurado en todos los m√≥dulos principales
- **Error Handling**: HTTPException para API, try-catch en servicios
- **Type Hints**: Utilizados en funciones cr√≠ticas
- **Docstrings**: Documentaci√≥n completa en estilo Google

### Variables de Entorno

```bash
# .env (opcional)
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO
CACHE_DIR=models_cache
```

### Agregar Nuevas Funcionalidades

1. **Nuevo Endpoint**:

   - Agregar ruta en `src/api/routes/route.py`
   - Crear schema en `src/api/schemas/model_schemas.py`
   - Documentar en este README

2. **Nuevo Modelo**:
   - Agregar l√≥gica en `src/model/`
   - Integrar con `prediction_service.py`
   - Actualizar tests

## üß™ Testing

### Pruebas unitarias

(`test_api.py`)

1. En este test se hacen tests con `test_e2e_prediction()` Y con `test_health_endpoint()` para ver que la respuesta del modelo sea la esperada.

(`test_interface.py`) 2. En este test se busca que al hacer una prediccion nos de alguna de estas etiquetas Positive, Negative o Neutral.

(`test_model`) 3. En este test se busca que las predicciones del modelo sean correctas y validas.

## üîß Troubleshooting

### Problemas Comunes

1. **Error de numpy.int64 serialization**

   - **Causa**: FastAPI no puede serializar tipos NumPy
   - **Soluci√≥n**: Ya implementado - conversi√≥n a `int()` nativo

2. **Modelos no se cargan**

   - **Causa**: Rutas incorrectas o archivos faltantes
   - **Soluci√≥n**: Verificar estructura de carpetas y paths

3. **Memoria insuficiente**

   - **Causa**: Datasets muy grandes
   - **Soluci√≥n**: Reducir `batch_size` en procesamiento

4. **Lentitud en primera predicci√≥n**
   - **Causa**: Descarga/carga inicial de modelos
   - **Soluci√≥n**: Normal, predicciones siguientes ser√°n r√°pidas

### Logs de Debug

```bash
# Ver logs detallados
export LOG_LEVEL=DEBUG
python src/api/main.py
```

## üìà M√©tricas y Monitoreo

### M√©tricas del Modelo

- **Accuracy**: Precisi√≥n general del modelo
- **Precision**: Precisi√≥n por clase (weighted)
- **Recall**: Recall por clase (weighted)
- **F1-Score**: Score F1 (weighted)
- **Confusion Matrix**: Matriz de confusi√≥n

### Uso de M√©tricas

```python
from src.models.utils import model_metrics

# y_true: etiquetas reales
# y_pred: predicciones del modelo
model_metrics(y_true, y_pred)
```

## üöß Roadmap

### Pr√≥ximas Funcionalidades

- [ ] **Interfaz Gradio** completamente funcional
- [ ] **Balanceado de datasets** autom√°tico
- [ ] **Soporte para m√°s idiomas**
- [ ] **API de entrenamiento** para modelos personalizados
- [ ] **M√©tricas en tiempo real** con dashboard
- [ ] **Docker containerization**
- [ ] **Deployment scripts** para producci√≥n

### Mejoras T√©cnicas

- [ ] **Tests unitarios** completos
- [ ] **CI/CD pipeline** con GitHub Actions
- [ ] **Monitoreo de performance** con Prometheus
- [ ] **Rate limiting** en API
- [ ] **Autenticaci√≥n** y autorizaci√≥n
- [ ] **Versionado de modelos** con MLflow

## ü§ù Contribuci√≥n

### C√≥mo Contribuir

1. Fork el repositorio
2. Crear rama de feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit los cambios (`git commit -am 'Add nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

### Gu√≠as de Desarrollo

- Seguir PEP 8 para estilo de c√≥digo Python
- Agregar docstrings a todas las funciones p√∫blicas
- Incluir tests para nuevas funcionalidades
- Actualizar este README si es necesario

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## üìû Soporte

Si tienes problemas o preguntas:

1. Revisa la secci√≥n [Troubleshooting](#troubleshooting)
2. Busca en Issues existentes
3. Crea un nuevo Issue con detalles espec√≠ficos
4. Incluye logs y pasos para reproducir el problema

---

**Desarrollado con ‚ù§Ô∏è usando Python, FastAPI, LightGBM y Sentence Transformers**
